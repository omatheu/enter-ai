# ENTER AI - Document Extraction API

Sistema de extraÃ§Ã£o inteligente de dados de documentos PDF usando IA, desenvolvido como projeto Fellowship ENTER AI.

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [Tecnologias](#tecnologias)
- [PrÃ©-requisitos](#prÃ©-requisitos)
- [InstalaÃ§Ã£o e ExecuÃ§Ã£o](#instalaÃ§Ã£o-e-execuÃ§Ã£o)
  - [OpÃ§Ã£o 1: Docker (Recomendado)](#opÃ§Ã£o-1-docker-recomendado)
  - [OpÃ§Ã£o 2: Ambiente Local](#opÃ§Ã£o-2-ambiente-local)
- [Uso da API](#uso-da-api)
- [Frontend](#frontend)
- [Testes](#testes)
- [Estrutura do Projeto](#estrutura-do-projeto)

---

## ğŸ¯ VisÃ£o Geral

Este projeto Ã© uma API de extraÃ§Ã£o de dados de documentos PDF que utiliza:
- **ExtraÃ§Ã£o de texto**: PDFPlumber para parsing de PDFs
- **IA Generativa**: OpenAI GPT para extraÃ§Ã£o inteligente de campos
- **Schemas flexÃ­veis**: DefiniÃ§Ã£o customizÃ¡vel de campos a serem extraÃ­dos
- **Interface web**: Frontend interativo para testes

### Funcionalidades

- âœ… ExtraÃ§Ã£o de campos estruturados de PDFs
- âœ… Suporte para mÃºltiplos tipos de documentos (Carteira OAB, Telas de Sistema, etc.)
- âœ… Modo Batch: processar mÃºltiplos PDFs de uma vez
- âœ… Modo Single: processar um PDF por vez
- âœ… Export de resultados em JSON e CSV
- âœ… Interface web moderna e responsiva

---

## ğŸ› ï¸ Tecnologias

### Backend
- **Python 3.12**
- **FastAPI**: Framework web moderno e rÃ¡pido
- **PDFPlumber**: ExtraÃ§Ã£o de texto e tabelas de PDFs
- **OpenAI API**: Modelos GPT para extraÃ§Ã£o inteligente
- **Pydantic**: ValidaÃ§Ã£o de dados e serializaÃ§Ã£o

### Frontend
- **HTML5 + CSS3 + JavaScript**: Interface web pura (sem frameworks)
- **Design responsivo**: Funciona em desktop e mobile

### DevOps
- **Docker & Docker Compose**: ContainerizaÃ§Ã£o
- **Nginx**: Servidor web para frontend

---

## ğŸ“¦ PrÃ©-requisitos

### Para Docker (Recomendado)
- Docker Engine 20.10+
- Docker Compose 1.29+

### Para Ambiente Local
- Python 3.12+
- Node.js 18+ (opcional, apenas para frontend)
- OpenAI API Key

---

## ğŸš€ InstalaÃ§Ã£o e ExecuÃ§Ã£o

### OpÃ§Ã£o 1: Docker (Recomendado)

#### 1. Clone o repositÃ³rio
```bash
git clone <repository-url>
cd enter-ai
```

#### 2. Configure a API Key
Certifique-se de que o arquivo `backend/.env` existe e contÃ©m sua OpenAI API Key:
```bash
# backend/.env
OPENAI_API_KEY=sk-your-openai-api-key-here
```

#### 3. Inicie os serviÃ§os
```bash
docker-compose up --build
```

#### 4. Acesse a aplicaÃ§Ã£o
- **Frontend**: http://localhost:8080
- **Backend API**: http://localhost:8001
- **DocumentaÃ§Ã£o da API**: http://localhost:8001/docs

#### Comandos Ãºteis
```bash
# Parar os serviÃ§os
docker-compose down

# Ver logs
docker-compose logs -f

# Rebuildar apenas o backend
docker-compose up --build backend

# Rodar em segundo plano
docker-compose up -d
```

---

### OpÃ§Ã£o 2: Ambiente Local

#### Backend

1. **Navegue atÃ© o diretÃ³rio do backend**
```bash
cd backend
```

2. **Crie e ative o ambiente virtual**
```bash
python3 -m venv .venv
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate  # Windows
```

3. **Instale as dependÃªncias**
```bash
pip install -r requirements.txt
```

4. **Configure a API Key**
```bash
cp .env.example .env
# Edite .env e adicione sua OPENAI_API_KEY
```

5. **Inicie o servidor**
```bash
uvicorn main:app --reload --port 8001
```

A API estarÃ¡ disponÃ­vel em http://localhost:8001

#### Frontend

1. **Navegue atÃ© o diretÃ³rio do frontend**
```bash
cd frontend
```

2. **Sirva os arquivos estÃ¡ticos**

OpÃ§Ã£o A - Python SimpleHTTPServer:
```bash
python3 -m http.server 8080
```

OpÃ§Ã£o B - Node.js http-server:
```bash
npx http-server -p 8080
```

O frontend estarÃ¡ disponÃ­vel em http://localhost:8080

---

## ğŸ“¡ Uso da API

### Endpoint: POST /extract

Extrai campos de um documento PDF.

#### Exemplo com cURL:
```bash
curl -X POST http://localhost:8001/extract \
  -F "label=carteira_oab" \
  -F "extraction_schema={\"nome\":\"Nome do profissional\",\"inscricao\":\"NÃºmero de inscriÃ§Ã£o\"}" \
  -F "pdf_file=@./docs/files/oab_1.pdf"
```

#### Exemplo com HTTPie:
```bash
http --form POST :8001/extract \
  label=carteira_oab \
  extraction_schema='{"nome": "Nome do profissional", "inscricao": "NÃºmero de inscriÃ§Ã£o"}' \
  pdf_file@./docs/files/oab_1.pdf
```

#### Resposta:
```json
{
  "label": "carteira_oab",
  "results": [
    {
      "field_name": "nome",
      "value": "JOANA D'ARC",
      "source": "llm",
      "confidence": 0.0
    },
    {
      "field_name": "inscricao",
      "value": "101943",
      "source": "llm",
      "confidence": 0.0
    }
  ],
  "flat": {
    "nome": "JOANA D'ARC",
    "inscricao": "101943"
  },
  "metadata": {
    "model": "gpt-5-mini",
    "prompt_tokens": 210,
    "completion_tokens": 40,
    "total_tokens": 250,
    "duration_ms": 2400,
    "source": "mixed",
    "extracted_at": "2025-11-06T15:30:00",
    "profiling": {
      "pdf_text_ms": 8,
      "heuristics_ms": 2,
      "llm_ms": 2100,
      "total_ms": 2400
    }
  }
}
```
> O frontend utiliza o objeto `flat` para mostrar o JSON â€œlimpoâ€, mas o payload completo mantÃ©m `results` (com fonte/confianÃ§a) e `metadata.profiling`.

---

## ğŸ¨ Frontend

O frontend oferece duas interfaces:

### 1. Modo Batch (PadrÃ£o)
- Upload de mÃºltiplos PDFs
- Schema em formato array (matching dataset.json)
- Processamento em lote
- Resumo agregado dos resultados

### 2. Modo Single
- Upload de um Ãºnico PDF
- Schema em formato objeto simples
- Ideal para testes rÃ¡pidos

### Funcionalidades
- âœ… Drag & drop de arquivos
- âœ… ValidaÃ§Ã£o de schemas JSON
- âœ… VisualizaÃ§Ã£o simultÃ¢nea (JSON achatado + detalhes completos)
- âœ… Export para JSON e CSV
- âœ… Exemplos prÃ©-carregados
- âœ… MÃ©tricas de performance (tempo, custo, tokens) e progresso em tempo real no modo batch

---

## ğŸ§ª Testes

### Testes Automatizados
```bash
cd backend
source .venv/bin/activate
pytest
```

### Testes Manuais

#### 1. Script de exemplo (usa dataset.json)
```bash
cd backend
source .venv/bin/activate
python3 scripts/run_example.py
```

#### 2. Frontend web
Acesse http://localhost:8080 e:
1. Clique em "Load Example"
2. FaÃ§a upload dos PDFs correspondentes
3. Clique em "Extract Data"

---

## ğŸ§± Arquitetura & Trade-offs

- **HeurÃ­sticas primeiro**: campos padronizados (CPF, seccional, subseÃ§Ã£o, etc.) sÃ£o extraÃ­dos via regex flexÃ­veis. Apenas valores de baixa confianÃ§a entram no lote LLM.
- **Contexto compacto**: o texto do PDF Ã© reduzido a janelas relevantes (com normalizaÃ§Ã£o de acentos) antes de chamar o LLM e durante o recovery. Isso mantÃ©m o total de tokens e o `duration_ms` dentro da meta de 2â€“5â€¯s.
- **Cache multinÃ­vel**: resultados completos (label+schema) e conteÃºdo dos PDFs ficam em memÃ³ria. A primeira execuÃ§Ã£o aprende padrÃµes; as seguintes respondem instantaneamente.
- **RecuperaÃ§Ã£o paralela**: quando um campo crÃ­tico falha, as tentativas de recuperaÃ§Ã£o sÃ£o disparadas em paralelo (heurÃ­sticas relaxadas â†’ prompt dedicado â†’ contexto expandido). As decisÃµes sÃ£o logadas como `Field <nome> | recovery_success`.
- **Observabilidade**: `metadata.profiling` acompanha cada resposta, enquanto o backend escreve logs estruturados para cache hits, heurÃ­sticas, LLM e recovery (`docker-compose logs -f backend`).
- **UX responsiva**: o frontend mostra o JSON achatado (`flat`), mantÃªm os detalhes para exportaÃ§Ãµes e processa lotes com atÃ© trÃªs uploads simultÃ¢neos, exibindo progresso parcial.

---

## ğŸ“ Estrutura do Projeto

```
enter-ai/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ extractors/       # LÃ³gica de extraÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ services/          # OrquestraÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ models.py          # Modelos Pydantic
â”‚   â”‚   â””â”€â”€ config.py          # ConfiguraÃ§Ãµes
â”‚   â”œâ”€â”€ tests/                 # Testes automatizados
â”‚   â”œâ”€â”€ scripts/               # Scripts utilitÃ¡rios
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ .env                   # ConfiguraÃ§Ãµes (nÃ£o versionado)
â”‚   â””â”€â”€ main.py                # Entry point da API
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html             # Interface web
â”‚   â””â”€â”€ public/                # Assets estÃ¡ticos
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ dataset.json       # Dataset de exemplos
â”‚   â””â”€â”€ files/                 # PDFs de exemplo
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ nginx.conf
â””â”€â”€ README.md
```

---

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### VariÃ¡veis de Ambiente (backend/.env)

```bash
# OpenAI Configuration
OPENAI_API_KEY=sk-your-key-here
```

### Modelos Suportados
- Todos da OPEN AI

---

## ğŸ“ Notas de Desenvolvimento

### Modo de Desenvolvimento com Docker

O docker-compose.yml inclui volumes para hot-reload:
```yaml
volumes:
  - ./backend/app:/app/app  # AlteraÃ§Ãµes no cÃ³digo refletem automaticamente
```

Para produÃ§Ã£o, comente esta linha.

### Troubleshooting

**Problema**: API nÃ£o carrega configuraÃ§Ãµes
**SoluÃ§Ã£o**: Verifique se o arquivo `.env` estÃ¡ no diretÃ³rio `backend/`

**Problema**: Modelo nÃ£o disponÃ­vel
**SoluÃ§Ã£o**: Verifique sua conta OpenAI e atualize `OPENAI_MODEL` no `.env`

**Problema**: CORS errors no frontend
**SoluÃ§Ã£o**: Certifique-se de que o Nginx estÃ¡ configurado corretamente (nginx.conf)

---

## ğŸ“„ LicenÃ§a

Este projeto foi desenvolvido como parte do Fellowship ENTER AI.

---

## ğŸ‘¤ Autor

**Matheus** - Fellowship ENTER AI 2025

---

## ğŸ™ Agradecimentos

- ENTER AI pelo desafio e oportunidade
- OpenAI pela API de IA
- Comunidade open source pelas ferramentas incrÃ­veis
